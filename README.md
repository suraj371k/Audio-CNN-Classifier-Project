# Audio CNN Classifier & Visualizer 

[![Model Accuracy](https://img.shields.io/badge/Model%20Accuracy-83.4%25-brightgreen.svg)]()
[![Next.js](https://img.shields.io/badge/Next.js-15-blue.svg)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19-blue.svg)](https://reactjs.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-orange.svg)](https://pytorch.org/)
[![Modal](https://img.shields.io/badge/Modal-Serverless-red.svg)](https://modal.com/)

**Production-ready audio-CNN classification** trained on **ResNet architecture** which i **created from scratch**, then trained the model on **ESC-50 DATASET** achieving **83.4% accuracy**. Live **feature map visualization**, **ResNet-50**, **Modal serverless**, **TensorBoard**, **Next.js 15 + React 19**.

---

##  Features

- **83.4% Top-1 Accuracy** on ESC-50 (50 environmental sounds)
- **Live Feature Maps** - Watch ResNet-50 layers activate
- **Real-time Waveform** + Mel Spectrogram visualization
- **50-class Emoji Support** üê¶üëèüöÅüî® (chirping_birds, clapping, etc.)
- **Modal A10G GPU** serverless inference (~45ms)
- **Next.js 15 App Router** + React 19 + TypeScript + shadcn/ui + Tailwind CSS 4
- **Base64 WAV** upload ‚Üí instant predictions
---
##  Performance

| Metric | Value |
|--------|-------|
| **Top-1 Accuracy** | **83.4%** |
| Inference Time | **45ms** (A10G) |
| Classes | 50 |
| Input Length | 5s WAV (44.1kHz) |
| Spectrogram | 128 mel bins |

---

**Sample Output (clapping.wav):**
üëè clapping: 81.63%
üë£ footsteps: 18.36%
ü•´ can_opening: 0.01%

---
#  UI Components

![UI Demo 1](UIDemos/Screenshot%202026-02-02%20035446.png)

![UI Demo 2](UIDemos/Screenshot%202026-02-02%20035458.png)  

![UI Demo 3](UIDemos/Screenshot%202026-02-02%20035507.png)

![UI Demo 4](UIDemos/Screenshot%202026-02-02%20035517.png)

---

## From-Scratch ResNet-50

**100% custom implementation** (no torchvision):

‚úÖ ResidualBlock: conv‚ÜíBN‚ÜíReLU + dynamic 1√ó1 shortcut
‚úÖ Pre-activation ordering (BN‚ÜíReLU‚ÜíConv)
‚úÖ ModuleList for feature map collection
‚úÖ Exact ResNet-50: 3-4-6-3 blocks,
64‚Üí128‚Üí256‚Üí512 channels
‚úÖ Audio-specific: 1ch input, AdaptiveAvgPool2d(1,1)


---

##  Architecture

**ResNet-50 for Audio Spectrograms** (3-4-6-3 blocks):

`Conv1(7√ó7,64) ‚Üí Layer1(3√ó64ch) ‚Üí Layer2(4√ó128ch) ‚Üí Layer3(6√ó256ch) ‚Üí Layer4(3√ó512ch)`
‚Üì
`AdaptiveAvgPool2d ‚Üí Dropout(0.5) ‚Üí FC(512‚Üí50) ‚Üí Softmax`

--- 
**Audio Pipeline:**
`WAV ‚Üí Mono ‚Üí Resample(44.1kHz) ‚Üí MelSpec(n_mels=128,n_fft=1024,hop=512) ‚Üí dB ‚Üí ResNet`

---

##  Quick Start

```bash
git clone https://github.com/harshit7271/Audio-CNN-Classifier-Project.git
cd Audio-CNN-Classifier-Project
```

### Backend (Modal)
```bash
pip install -r requirements.txt
modal token set
modal volume put esc-model best_model.pth
modal deploy main.py
```

### Frontend
```bash
cd audio-cnn-frontend
pnpm install
pnpm dev
```

**Frontend Stack:**
- **Next.js 15.2.3** - App Router with Turbo mode
- **React 19.0.0** - Latest React with concurrent features
- **TypeScript 5.8.2** - Strict type checking
- **Tailwind CSS 4.0.15** - Utility-first styling
- **shadcn/ui** - Accessible component library (Badge, Button, Card, Progress)
- **Radix UI** - Unstyled, accessible primitives
- **T3 Stack** - Type-safe environment validation
- **Geist Font** - Modern typography

---
## Structure
```
‚îú‚îÄ‚îÄ audio-cnn-frontend/              # Next.js 15 + React 19 (T3 Stack)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx             # Main page with file upload & visualization
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layout.tsx           # Root layout with Geist font
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ FeatureMap.tsx   # SVG-based feature map visualization
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Waveform.tsx     # Audio waveform SVG renderer
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ColorScale.tsx   # Gradient color legend
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ badge.tsx        # shadcn/ui Badge component
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ button.tsx       # shadcn/ui Button component
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ card.tsx         # shadcn/ui Card component
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ progress.tsx     # shadcn/ui Progress component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.ts             # cn() utility (clsx + tailwind-merge)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ colors.ts            # Feature map color mapping (RGB gradients)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ styles/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ globals.css          # Tailwind CSS imports
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ env.js                   # T3-OSS environment validation
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ favicon.ico
‚îÇ   ‚îú‚îÄ‚îÄ package.json                 # Dependencies & scripts
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json                # TypeScript config (path aliases: ~/*)
‚îÇ   ‚îú‚îÄ‚îÄ next.config.js               # Next.js configuration
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js           # Tailwind CSS configuration
‚îÇ   ‚îî‚îÄ‚îÄ components.json              # shadcn/ui configuration

‚îú‚îÄ‚îÄ backend/                         # Modal + PyTorch
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # FastAPI + AudioClassifier endpoint
‚îÇ   ‚îú‚îÄ‚îÄ train.py                     # Training script
‚îÇ   ‚îú‚îÄ‚îÄ model.py                     # ResNet-50 (16 blocks)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pth               # 83.4% checkpoint (on Modal volume)
‚îÇ
‚îú‚îÄ‚îÄ tensorboard_logs/                # Training logs
‚îÇ   ‚îî‚îÄ‚îÄ run_*/                       # TensorBoard event files
‚îÇ
‚îú‚îÄ‚îÄ UIDemos/                         # UI screenshots
‚îÇ   ‚îî‚îÄ‚îÄ Screenshot*.png
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

# Code Highligths
### Backend(main.py)
```python
# Base64 ‚Üí WAV ‚Üí MelSpec ‚Üí ResNet ‚Üí Feature Maps
audio_bytes = base64.b64decode(request.audio_data)
spectrogram = MelSpectrogram(sample_rate=44100, n_mels=128)
output, feature_maps = model(spectrogram, return_feature_maps=True)
```

## Frontend (Next.js 15 + React 19)
```tsx
// File upload ‚Üí Base64 encoding ‚Üí API call
const reader = new FileReader();
reader.readAsArrayBuffer(file);
reader.onload = async () => {
  const arrayBuffer = reader.result as ArrayBuffer;
  const base64String = btoa(
    new Uint8Array(arrayBuffer).reduce(
      (data, byte) => data + String.fromCharCode(byte), ""
    )
  );
  
  const response = await fetch(API_ENDPOINT, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ audio_data: base64String })
  });
  
  const { predictions, visualization, input_spectrogram, waveform } = 
    await response.json();
};

// Layer splitting for visualization
function splitLayers(visualization) {
  const main = [];      // Top-level layers (conv1, layer1, etc.)
  const internals = {}; // Internal layers (layer1.0.conv1, etc.)
  // Groups layers by parent block for nested visualization
}
```

**Frontend Features:**
- **Client-side WAV upload** with FileReader API
- **Base64 encoding** for audio transmission
- **Real-time feature map visualization** via SVG rendering
- **Interactive layer exploration** (main layers + internal block layers)
- **Top 3 predictions** with confidence progress bars
- **50-class emoji mapping** (ESC-50 categories)
- **Responsive grid layout** (Tailwind CSS)
- **Color-coded feature maps** (blue‚Üíwhite‚Üíorange gradient)
- **Waveform visualization** (SVG path rendering)
- **Error handling** with user-friendly messages
- **Loading states** during API inference
---

# Key Features
- GPU Autoscaling - Modal scales to zero

- NaN Handling - `torch.nan_to_num()` for robust inference

- Stereo‚ÜíMono - `np.mean(audio_data, axis=1)`

- Waveform Downsampling - Max 8000 samples for viz

- **Layer Splitting** - `splitLayers()` groups main layers vs internal block layers for nested visualization
- **ESC-50 Emojis** - 50-class mapping (üêïüåßÔ∏èüë∂üö™ etc.) with fallback icons
- **SVG-based Visualizations** - FeatureMap & Waveform use scalable SVG rendering
- **Color Gradient Mapping** - Custom RGB interpolation for feature map values (-1 to +1)
- **Responsive Design** - Mobile-friendly grid layouts with Tailwind CSS
- **Type Safety** - Full TypeScript coverage with strict mode enabled
- **Path Aliases** - `~/*` imports for cleaner code organization

---
# Training
```bash
Dataset: ESC-50 (2000 clips, 5s, 44.1kHz)
Splits: 5-fold CV (Fold 5 = test)
Best: Epoch 100, Val Acc: 83.4%
```
---


---
# License
MIT - Use freely!

